{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is used by get_new_raw_file.py to create a report after checking a new download.  To make this work nicely,\n",
    "# you should use the 'hide-input-all' nbextension and before get_new_raw_file, enable hide all, reset and clear\n",
    "# all cells, save the sheet, and CLose and Halt.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, floor\n",
    "def round_sig(x, sig=2):\n",
    "    try:\n",
    "        if abs(x)>=1:\n",
    "            out =  int(round(x, sig-int(floor(log10(abs(x))))-1))\n",
    "            return f\"{out:,d}\" # does the right thing with commas\n",
    "        else: # fractional numbers\n",
    "            return str(round(x, sig-int(floor(log10(abs(x))))-1))\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "# used to insert links of google maps into tables\n",
    "def make_clickable(val):\n",
    "    try:\n",
    "        if val[:4]=='http':\n",
    "            return '<a href=\"{}\" target=\"_blank\">{}</a>'.format(val,'map')\n",
    "    except:\n",
    "        return val\n",
    "    return val\n",
    "\n",
    "def getLink(row):\n",
    "    return ggmap.getSearchLink(row.Latitude,row.Longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preamble to analysis\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500) \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "from IPython.display import Markdown as md\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "now = datetime.now()\n",
    "one_year_ago = now-timedelta(days=365)\n",
    "today = str(datetime.today())\n",
    "today = today.split()[0]\n",
    "import core.get_google_map as ggmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'# FracFocus bulk download summary report for {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These reports are generated roughly 4 times a week.** If you need the reports more frequently, let me know...\n",
    "\n",
    "Note that if you have visited this page before, you may need to clear your browser's queue for the most recent results.  For many browsers, just type 'Ctrl-F5'.\n",
    "\n",
    "The following data are from the most recently **published** fracking events. These are still raw names and numbers and have not yet been checked for validity. To see cleaned data set, [go here.](https://qbobioyuz1dh57rst8exeg-on.drv.tw/open_FF_catalog/)\n",
    "\n",
    "In many cases below, individual fracking disclosures are identified by APINumber.  If you are interested in seeing the details of the raw data, use that APINumber at the FracFocus [\"Find a Well\" site](https://fracfocusdata.org/DisclosureSearch/Search.aspx).  This search site will deliver pdf files of individual fracking events to your computer with most of the same raw data available used here from the bulk download.\n",
    "\n",
    "In many of the tables of individual disclosures, a link is provided to a Google map of the location provided in the disclosure.  To see a satellite view of the location, click the 'satellite' mode button in the lower right of the Google Maps page.  Note that many of the fracking sites on this page are **newer** than the satellite image that Google uses, and the well pad will not be visible.  However, the user can still get an idea of the geographic context of the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastrunfn = 'last_daily_run.txt'\n",
    "try:\n",
    "    with open(lastrunfn,'r') as f:\n",
    "        lastrun = f.readline().strip()\n",
    "except:\n",
    "    lastrun = ' ----- '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = './sources/'\n",
    "datefn= './sources/upload_dates.csv'\n",
    "currfn = 'testData'\n",
    "outdir = './out/'\n",
    "tempfolder = './tmp/'\n",
    "webworkfolder = './website_gen/'\n",
    "zfilename = 'testData'\n",
    "\n",
    "updates = pd.read_csv(datefn)\n",
    "updates['dt_added'] = pd.to_datetime(updates.date_added)\n",
    "updates['days_old'] = (now - updates.dt_added).dt.days\n",
    "new_upk = updates[updates.date_added==today].UploadKey.tolist()\n",
    "month_upk = updates[updates.days_old<31].UploadKey.tolist()\n",
    "#print(new_upk)\n",
    "#md(f'### Number of new disclosures added yesterday: {len(new_upk)}')\n",
    "md(f'### Number of new disclosures added since last download ({lastrun}): {len(new_upk)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets make today's list\n",
    "\n",
    "import core.Construct_set as const_set\n",
    "t = const_set.Construct_set(fromScratch=False,\n",
    "                            zfilename=zfilename,\n",
    "                            sources=sources,\n",
    "                            outdir=outdir,\n",
    "                            tempfolder=tempfolder).get_full_set();\n",
    "with open(lastrunfn,'w') as f:\n",
    "    f.write(f'{today}\\n')\n",
    "df = t.tables['allrec'].get_df()\n",
    "# locat = t.get_df_location()[['UploadKey','StateName','CountyName',\n",
    "#                              'iOperatorName','iUploadKey','TotalBaseWaterVolume',\n",
    "#                              'FederalWell']]\n",
    "locat = t.tables['event'].get_df()[['UploadKey','StateName','CountyName','APINumber',\n",
    "                                    'iOperatorName','iUploadKey','TotalBaseWaterVolume',\n",
    "                                    'FederalWell','IndianWell','JobEndDate','Latitude','Longitude']]\n",
    "df = pd.merge(df,locat,on='iUploadKey',how='left')\n",
    "casdf = t.tables['cas'].get_df()\n",
    "df = pd.merge(df,casdf,on='iCASNumber',how='left')\n",
    "\n",
    "df['end_date'] = df.JobEndDate.str.split().str[0]\n",
    "df['date'] = pd.to_datetime(df.JobEndDate,errors='coerce')\n",
    "todaydf = df[df.UploadKey.isin(new_upk)]\n",
    "opdf = t.tables['operator'].get_df()\n",
    "todaydf = pd.merge(todaydf,opdf,on='iOperatorName',how='left')\n",
    "if len(todaydf)>0:\n",
    "    todaydf['map_link'] = todaydf.apply(lambda x: getLink(x),axis=1)\n",
    "else:\n",
    "    todaydf['map_link'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch proprietary labels\n",
    "caslab = pd.read_csv('./sources/cas_labels.csv')\n",
    "caslab.proprietary = np.where(caslab.proprietary==1,True,False)\n",
    "prop_lab = list(caslab[caslab.proprietary].clean.unique())\n",
    "df['proprietary'] = df.CASNumber.str.strip().str.lower().isin(prop_lab)\n",
    "\n",
    "from core.CAS_tools import correct_zeros\n",
    "# fetch authenticated cas numbers\n",
    "casref = pd.read_csv('./sources/CAS_ref_and_names.csv',quotechar='$')\n",
    "cas_ok = list(casref.cas_number.unique())\n",
    "df['cleanedcas'] = df.CASNumber.str.strip().str.lower()\n",
    "df.cleanedcas = df.cleanedcas.map(lambda x: correct_zeros(x))\n",
    "df['clean_cas'] = df.cleanedcas.isin(cas_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb = todaydf.groupby(['UploadKey','StateName'],as_index=False)[['CountyName',\n",
    "                                                           'OperatorName','APINumber',\n",
    "                                                  'TotalBaseWaterVolume',\n",
    "                                                  'FederalWell','IndianWell','map_link']].first()\n",
    "# tmp1 = gb.groupby(['StateName','CountyName','OperatorName'],as_index=False)['UploadKey'].count()\n",
    "# tmp1.rename({'UploadKey':'num_new_Disclosures'},inplace=True,axis=1)\n",
    "# tmp2 = gb.groupby(['StateName','CountyName','OperatorName'],\n",
    "#           as_index=False)['TotalBaseWaterVolume'].mean()\n",
    "# tmp2.rename({'TotalBaseWaterVolume':'mean_Water_Used_gal'},axis=1,inplace=True)\n",
    "# tmp2.mean_Water_Used_gal = tmp2.mean_Water_Used_gal.map(lambda x: round_sig(x,3))\n",
    "# out = pd.merge(tmp1,tmp2,on=['StateName','CountyName','OperatorName'],how='left')\n",
    "\n",
    "# if len(out)>0:\n",
    "#     display(md(\"\"\"The following list is the most recently published fracking events. Note that these are still\n",
    "# raw names and numbers and have not yet been checked for validity.\"\"\"))\n",
    "#     display(out)\n",
    "\n",
    "if len(gb)>0:\n",
    "    display(md(\"\"\"The following list is the most recently published fracking events. Note that these are still\n",
    "raw names and numbers and have not yet been checked for validity.\"\"\"))\n",
    "    t = gb[['StateName','CountyName','OperatorName','APINumber','TotalBaseWaterVolume','map_link']].copy()\n",
    "    t = t.sort_values(['StateName','CountyName','OperatorName'])\n",
    "    display(t.style.format(make_clickable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gb)>0:\n",
    "    gb['Water_vol_gallons'] = gb.TotalBaseWaterVolume.map(lambda x: round_sig(x,3))\n",
    "    gb['isFedWell'] = gb.FederalWell=='True'\n",
    "    if gb.isFedWell.sum()>0:\n",
    "#        display(md('# Disclosures published yesterday for fracking on US Federal lands'))\n",
    "        display(md('# Disclosures published recently for fracking on US Federal lands'))\n",
    "        display(gb[gb.isFedWell][['StateName','CountyName','OperatorName',\n",
    "                                    'APINumber','Water_vol_gallons']])\n",
    "    else:\n",
    "        display(md('None of the disclosures above are on Federal Lands.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gb)>0:\n",
    "    gb['Water_vol_gallons'] = gb.TotalBaseWaterVolume.map(lambda x: round_sig(x,3))\n",
    "    gb['isIndWell'] = gb.IndianWell==True\n",
    "    if gb.isIndWell.sum()>0:\n",
    "#        display(md('# Disclosures published yesterday for fracking on US Federal lands'))\n",
    "        display(md('# Disclosures published recently labeled as \"Indian Well\"'))\n",
    "        display(gb[gb.isIndWell][['StateName','CountyName','OperatorName',\n",
    "                                   'APINumber','Water_vol_gallons']])\n",
    "    else:\n",
    "        display(md('None of the disclosures above are of \"Indian Wells.\"'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df[df.UploadKey.isin(month_upk)].copy()\n",
    "monthdf['map_link'] = monthdf.apply(lambda x: getLink(x),axis=1)\n",
    "# opdf = t.tables['operator'].get_df()\n",
    "monthdf = pd.merge(monthdf,opdf,on='iOperatorName',how='left')\n",
    "monthdf = pd.merge(monthdf,updates,on='UploadKey',how='left')\n",
    "# monthdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End dates for disclosures published in the past 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['date','APINumber','OperatorName','map_link']].first()\n",
    "ax = gb.date.hist()\n",
    "ax.set_title('Final dates for fracking jobs published in the last month')\n",
    "ax.set_ylabel = ('Number of disclosures published in last 30 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs finished more than a year ago but just published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = gb[gb.date<one_year_ago]\n",
    "t = old[['date','APINumber','OperatorName','map_link']].sort_values('date').head(100)\n",
    "t.style.format(make_clickable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proprietary Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proprietary summaries\n",
    "gb = monthdf.groupby('UploadKey',as_index=False)[['proprietary','clean_cas']].sum()\n",
    "gb['fraction_prop'] = gb.proprietary/(gb.clean_cas+gb.proprietary)\n",
    "gb['percent_proprietary'] = (gb.fraction_prop*100).round(1)\n",
    "ax = gb.fraction_prop.hist()\n",
    "ax.set_title('Fraction of disclosure records that are claimed as \"proprietary\"');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent disclosure with largest fractions of PROPRIETARY claims\n",
    "\"percent_proprietary\" represents the overall percentage of a proprietary claims for chemicals within a given disclosure. For example, 50% means the identity of half of all chemicals disclosed are hidden by the claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = pd.merge(gb,monthdf.groupby('UploadKey',as_index=False)[['APINumber','OperatorName','StateName','map_link']].first(),\n",
    "              on='UploadKey',how='left')\n",
    "t = mg[['percent_proprietary','APINumber','OperatorName',\n",
    "        'StateName','map_link']].sort_values('percent_proprietary',ascending=False).head(100)\n",
    "t.style.format(make_clickable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water use reported in disclosures in the past 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "monthdf = monthdf.groupby('UploadKey',as_index=False)[['TotalBaseWaterVolume','StateName']].first()\n",
    "sn = monthdf.groupby('StateName',as_index=False)['UploadKey'].count().astype('str')\n",
    "sn.columns = ['StateName', 'cnt']\n",
    "monthdf = pd.merge(monthdf,sn,on='StateName',how='left')\n",
    "monthdf['State_Num'] = monthdf.StateName+'__'+monthdf.cnt\n",
    "monthdf = monthdf.sort_values('cnt',ascending=False)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = sns.stripplot(monthdf.TotalBaseWaterVolume,monthdf.State_Num,jitter=.2,alpha=.4,size=10)\n",
    "plt.xlabel(f'water volume (gallons):',fontsize=14);\n",
    "plt.title(f'Water Use for events published in the last 30 days',fontsize=16)\n",
    "ax.set(xscale='log')\n",
    "ax.set(xlim=(max(1000,monthdf.TotalBaseWaterVolume.min()),monthdf.TotalBaseWaterVolume.max()*1.1))\n",
    "ax.grid(axis='y')\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "locmaj = matplotlib.ticker.LogLocator(base=10,subs='all') \n",
    "ax.xaxis.set_major_locator(locmaj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclosures published in the past 30 days with suspect values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero or no reported Base Water Use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df[df.UploadKey.isin(month_upk)]\n",
    "monthdf = pd.merge(monthdf,opdf,on='iOperatorName',how='left')\n",
    "monthdf = pd.merge(monthdf,updates,on='UploadKey',how='left')\n",
    "monthdf['map_link'] = monthdf.apply(lambda x: getLink(x),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['TotalBaseWaterVolume','APINumber',\n",
    "                                                  'StateName','OperatorName','end_date','map_link']].first()\n",
    "gb = gb.drop('UploadKey',axis=1)\n",
    "gb[gb.TotalBaseWaterVolume==0].sort_values(['StateName','TotalBaseWaterVolume']).style.format(make_clickable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Water Use is greater than 30 million gallons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['TotalBaseWaterVolume','APINumber',\n",
    "                                                  'StateName','OperatorName','end_date','map_link']].first()\n",
    "gb['Water_Volume_gallons'] = gb.TotalBaseWaterVolume.map(lambda x: round_sig(x,3))\n",
    "#gb['Probable Error'] = np.where(gb.TotalBaseWaterVolume>75000000,'<<<<<<<<<','')\n",
    "gb = gb[gb.TotalBaseWaterVolume>30000000].sort_values(['StateName','TotalBaseWaterVolume'])\n",
    "gb = gb.drop(['UploadKey','TotalBaseWaterVolume'],axis=1)\n",
    "gb.style.format(make_clickable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of record percentages don't add to roughly 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['APINumber',\n",
    "                                                  'StateName','OperatorName','map_link']].first()\n",
    "gb1 = monthdf.groupby('UploadKey',as_index=False)[['PercentHFJob']].sum()\n",
    "mg = pd.merge(gb1,gb,on='UploadKey')\n",
    "mg = mg.drop('UploadKey',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent sum is less than 90 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mg[mg.PercentHFJob<90].sort_values('PercentHFJob').style.format(make_clickable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent sum is greater than 110 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mg[mg.PercentHFJob>110].sort_values('PercentHFJob',ascending=False).style.format(make_clickable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New disclosures published per month since Jan. 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates['added'] = updates.dt_added.apply( lambda updates : datetime(year=updates.year, month=updates.month, day=updates.day))\n",
    "updates.set_index(updates[\"added\"],inplace=True)\n",
    "updates.drop('added',axis=1,inplace=True)\n",
    "counts = updates.resample('M').count()\n",
    "counts.reset_index(inplace=True)\n",
    "counts[counts.added.dt.year>2018].plot('added','UploadKey', title='Number of new disclosures');\n",
    "#counts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tripwire results from the latest download:\n",
    "### Comparing the latest bulk download with the previous one to try to detect \"silent changes\" -- that is, changes to already published disclosures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripdir = './out/tripwire_log/'\n",
    "outfn = now.strftime(\"%Y-%m-%d\")\n",
    "with open(tripdir+outfn+'.txt','r') as f:\n",
    "    txt = f.read()\n",
    "print(txt)"
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
