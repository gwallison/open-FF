{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is used by get_new_raw_file.py to create a report after checking a new download.  To make this work nicely,\n",
    "# you should use the 'hide-input-all' nbextension and before get_new_raw_file, enable hide all, reset and clear\n",
    "# all cells, save the sheet, and CLose and Halt.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, floor\n",
    "def round_sig(x, sig=2):\n",
    "    try:\n",
    "        if abs(x)>=1:\n",
    "            out =  int(round(x, sig-int(floor(log10(abs(x))))-1))\n",
    "            return f\"{out:,d}\" # does the right thing with commas\n",
    "        else: # fractional numbers\n",
    "            return str(round(x, sig-int(floor(log10(abs(x))))-1))\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preamble to analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "from IPython.display import Markdown as md\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "now = datetime.now()\n",
    "one_year_ago = now-timedelta(days=365)\n",
    "today = str(datetime.today())\n",
    "today = today.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'# FracFocus bulk download summary report for {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These reports are now generated about once each week.** If you need the reports more frequently, let me know...\n",
    "\n",
    "Note that if you have visited this page before, you may need to clear your browser's queue for the most recent results.  For many browsers, just type 'Ctrl-F5'.\n",
    "\n",
    "The following data are from the most recently **published** fracking events. These are still raw names and numbers and have not yet been checked for validity. To see cleaned data set, [go here.](https://qbobioyuz1dh57rst8exeg-on.drv.tw/open_FF_catalog/)\n",
    "\n",
    "In many cases below, individual fracking disclosures are identified by APINumber.  If you are interested in seeing the details of the raw data, use that APINumber at the FracFocus [\"Find a Well\" site](https://fracfocusdata.org/DisclosureSearch/Search.aspx).  This search site will deliver pdf files of individual fracking events to your computer with most of the same raw data available used here from the bulk download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastrunfn = 'last_daily_run.txt'\n",
    "try:\n",
    "    with open(lastrunfn,'r') as f:\n",
    "        lastrun = f.readline().strip()\n",
    "except:\n",
    "    lastrun = ' ----- '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = './sources/'\n",
    "datefn= './sources/upload_dates.csv'\n",
    "currfn = 'testData'\n",
    "outdir = './out/'\n",
    "tempfolder = './tmp/'\n",
    "webworkfolder = './website_gen/'\n",
    "zfilename = 'testData'\n",
    "\n",
    "updates = pd.read_csv(datefn)\n",
    "updates['dt_added'] = pd.to_datetime(updates.date_added)\n",
    "updates['days_old'] = (now - updates.dt_added).dt.days\n",
    "new_upk = updates[updates.date_added==today].UploadKey.tolist()\n",
    "month_upk = updates[updates.days_old<31].UploadKey.tolist()\n",
    "#print(new_upk)\n",
    "#md(f'### Number of new disclosures added yesterday: {len(new_upk)}')\n",
    "md(f'### Number of new disclosures added since last download ({lastrun}): {len(new_upk)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets make today's list\n",
    "\n",
    "import core.Construct_set as const_set\n",
    "t = const_set.Construct_set(fromScratch=False,\n",
    "                            zfilename=zfilename,\n",
    "                            sources=sources,\n",
    "                            outdir=outdir,\n",
    "                            tempfolder=tempfolder).get_full_set();\n",
    "with open(lastrunfn,'w') as f:\n",
    "    f.write(f'{today}\\n')\n",
    "df = t.tables['allrec'].get_df()\n",
    "# locat = t.get_df_location()[['UploadKey','StateName','CountyName',\n",
    "#                              'iOperatorName','iUploadKey','TotalBaseWaterVolume',\n",
    "#                              'FederalWell']]\n",
    "locat = t.tables['event'].get_df()[['UploadKey','StateName','CountyName','APINumber',\n",
    "                                    'iOperatorName','iUploadKey','TotalBaseWaterVolume',\n",
    "                                    'FederalWell','IndianWell','JobEndDate']]\n",
    "df = pd.merge(df,locat,on='iUploadKey',how='left')\n",
    "casdf = t.tables['cas'].get_df()\n",
    "df = pd.merge(df,casdf,on='iCASNumber',how='left')\n",
    "\n",
    "df['end_date'] = df.JobEndDate.str.split().str[0]\n",
    "df['date'] = pd.to_datetime(df.JobEndDate,errors='coerce')\n",
    "todaydf = df[df.UploadKey.isin(new_upk)]\n",
    "opdf = t.tables['operator'].get_df()\n",
    "todaydf = pd.merge(todaydf,opdf,on='iOperatorName',how='left')\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch proprietary labels\n",
    "caslab = pd.read_csv('./sources/cas_labels.csv')\n",
    "caslab.proprietary = np.where(caslab.proprietary==1,True,False)\n",
    "prop_lab = list(caslab[caslab.proprietary].clean.unique())\n",
    "df['proprietary'] = df.CASNumber.str.strip().str.lower().isin(prop_lab)\n",
    "\n",
    "# fetch authenticated cas numbers\n",
    "casref = pd.read_csv('./sources/CAS_ref_and_names.csv',quotechar='$')\n",
    "cas_ok = list(casref.cas_number.unique())\n",
    "df['clean_cas'] = df.CASNumber.str.strip().str.lower().isin(cas_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb = todaydf.groupby(['UploadKey','StateName'],as_index=False)[['CountyName',\n",
    "                                                           'OperatorName','APINumber',\n",
    "                                                  'TotalBaseWaterVolume',\n",
    "                                                  'FederalWell','IndianWell']].first()\n",
    "tmp1 = gb.groupby(['StateName','CountyName','OperatorName'],as_index=False)['UploadKey'].count()\n",
    "tmp1.rename({'UploadKey':'num_new_Disclosures'},inplace=True,axis=1)\n",
    "tmp2 = gb.groupby(['StateName','CountyName','OperatorName'],\n",
    "          as_index=False)['TotalBaseWaterVolume'].mean()\n",
    "tmp2.rename({'TotalBaseWaterVolume':'mean_Water_Used_gal'},axis=1,inplace=True)\n",
    "tmp2.mean_Water_Used_gal = tmp2.mean_Water_Used_gal.map(lambda x: round_sig(x,3))\n",
    "out = pd.merge(tmp1,tmp2,on=['StateName','CountyName','OperatorName'],how='left')\n",
    "\n",
    "if len(out)>0:\n",
    "    display(md(\"\"\"The following list is the most recently published fracking events. Note that these are still\n",
    "raw names and numbers and have not yet been checked for validity.\"\"\"))\n",
    "    display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gb)>0:\n",
    "    gb['Water_vol_gallons'] = gb.TotalBaseWaterVolume.map(lambda x: round_sig(x,3))\n",
    "    if gb.FederalWell.sum()>0:\n",
    "#        display(md('# Disclosures published yesterday for fracking on US Federal lands'))\n",
    "        display(md('# Disclosures published recently for fracking on US Federal lands'))\n",
    "        display(gb[gb.FederalWell][['StateName','CountyName','OperatorName',\n",
    "                                    'APINumber','Water_vol_gallons']])\n",
    "    else:\n",
    "        display(md('None of the disclosures above are on Federal Lands.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gb)>0:\n",
    "    gb['Water_vol_gallons'] = gb.TotalBaseWaterVolume.map(lambda x: round_sig(x,3))\n",
    "    if gb.IndianWell.sum()>0:\n",
    "#        display(md('# Disclosures published yesterday for fracking on US Federal lands'))\n",
    "        display(md('# Disclosures published recently labeled as \"Indian Well\"'))\n",
    "        display(gb[gb.IndianWell][['StateName','CountyName','OperatorName',\n",
    "                                   'APINumber','Water_vol_gallons']])\n",
    "    else:\n",
    "        display(md('None of the disclosures above are of \"Indian Wells.\"'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df[df.UploadKey.isin(month_upk)]\n",
    "# opdf = t.tables['operator'].get_df()\n",
    "monthdf = pd.merge(monthdf,opdf,on='iOperatorName',how='left')\n",
    "monthdf = pd.merge(monthdf,updates,on='UploadKey',how='left')\n",
    "# monthdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End dates for disclosures published in the past 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['date','APINumber','OperatorName']].first()\n",
    "ax = gb.date.hist()\n",
    "ax.set_title('Final dates for fracking jobs published in the last month')\n",
    "ax.set_ylabel = ('Number of disclosures published in last 30 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs finished more than a year ago but just published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = gb[gb.date<one_year_ago]\n",
    "display(old[['date','APINumber','OperatorName']].sort_values('date').head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proprietary Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proprietary summaries\n",
    "gb = monthdf.groupby('UploadKey',as_index=False)[['proprietary','clean_cas']].sum()\n",
    "gb['fraction_prop'] = gb.proprietary/(gb.clean_cas+gb.proprietary)\n",
    "ax = gb.fraction_prop.hist()\n",
    "ax.set_title('Fraction of disclosure records that are claimed as \"proprietary\"');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent disclosure with largest fractions of PROPRIETARY claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = pd.merge(gb,monthdf.groupby('UploadKey',as_index=False)[['APINumber','OperatorName','StateName']].first(),\n",
    "              on='UploadKey',how='left')\n",
    "display(mg[['fraction_prop','APINumber','OperatorName','StateName']].sort_values('fraction_prop',ascending=False).head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water use reported in disclosures in the past 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "monthdf = monthdf.groupby('UploadKey',as_index=False)[['TotalBaseWaterVolume','StateName']].first()\n",
    "sn = monthdf.groupby('StateName',as_index=False)['UploadKey'].count().astype('str')\n",
    "sn.columns = ['StateName', 'cnt']\n",
    "monthdf = pd.merge(monthdf,sn,on='StateName',how='left')\n",
    "monthdf['State_Num'] = monthdf.StateName+'__'+monthdf.cnt\n",
    "monthdf = monthdf.sort_values('cnt',ascending=False)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = sns.stripplot(monthdf.TotalBaseWaterVolume,monthdf.State_Num,jitter=.2,alpha=.4,size=10)\n",
    "plt.xlabel(f'water volume (gallons):',fontsize=14);\n",
    "plt.title(f'Water Use for events published in the last 30 days',fontsize=16)\n",
    "ax.set(xscale='log')\n",
    "ax.set(xlim=(max(1000,monthdf.TotalBaseWaterVolume.min()),monthdf.TotalBaseWaterVolume.max()*1.1))\n",
    "ax.grid(axis='y')\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "locmaj = matplotlib.ticker.LogLocator(base=10,subs='all') \n",
    "ax.xaxis.set_major_locator(locmaj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclosures published in the past 30 days with suspect values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero or no reported Base Water Use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df[df.UploadKey.isin(month_upk)]\n",
    "monthdf = pd.merge(monthdf,opdf,on='iOperatorName',how='left')\n",
    "monthdf = pd.merge(monthdf,updates,on='UploadKey',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['TotalBaseWaterVolume','APINumber',\n",
    "                                                  'StateName','OperatorName','end_date']].first()\n",
    "gb = gb.drop('UploadKey',axis=1)\n",
    "display(gb[gb.TotalBaseWaterVolume==0].sort_values(['StateName','TotalBaseWaterVolume']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Water Use is greater than 30 million gallons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['TotalBaseWaterVolume','APINumber',\n",
    "                                                  'StateName','OperatorName','end_date']].first()\n",
    "gb = gb.drop('UploadKey',axis=1)\n",
    "gb['Probable Error'] = np.where(gb.TotalBaseWaterVolume>75000000,'<<<<<<<<<','')\n",
    "display(gb[gb.TotalBaseWaterVolume>30000000].sort_values(['StateName','TotalBaseWaterVolume']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of record percentages don't add to roughly 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = monthdf.groupby('UploadKey',as_index=False)[['APINumber',\n",
    "                                                  'StateName','OperatorName']].first()\n",
    "gb1 = monthdf.groupby('UploadKey',as_index=False)[['PercentHFJob']].sum()\n",
    "mg = pd.merge(gb1,gb,on='UploadKey')\n",
    "mg = mg.drop('UploadKey',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent sum is less than 90 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mg[mg.PercentHFJob<90].sort_values('PercentHFJob'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent sum is greater than 110 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mg[mg.PercentHFJob>110].sort_values('PercentHFJob',ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New disclosures published per month since Jan. 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates['added'] = updates.dt_added.apply( lambda updates : datetime(year=updates.year, month=updates.month, day=updates.day))\n",
    "updates.set_index(updates[\"added\"],inplace=True)\n",
    "updates.drop('added',axis=1,inplace=True)\n",
    "counts = updates.resample('M').count()\n",
    "counts.reset_index(inplace=True)\n",
    "counts[counts.added.dt.year>2018].plot('added','UploadKey', title='Number of new disclosures');\n",
    "#counts.head()\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
